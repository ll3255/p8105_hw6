---
title: "Homework 6"
author: "LML"
date: "Nov 25 by 4:00pm"
output: github_document
---

Setup
```{r}
library(tidyverse)
library(modelr)
knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%"
)
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)
scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
theme_set(theme_minimal() + theme(legend.position = "bottom"))
set.seed(1)
```

# Problem 1

In the following chunck I load and tidy the dataset, creating factor variables for the categorical variables. I also quickly overview the data and check for missing data (there are none).
```{r}
child_data = 
  readr::read_csv("data/birthweight.csv") %>%
  janitor::clean_names() %>%
    mutate(
    babysex = factor(babysex, labels = c("male", "female")),
    frace = factor(frace, levels = c(1, 2, 3, 4, 8, 9), labels = c("White", "Black", "Asian"," Puerto Rican", "Other", "Unknown")),
    malform = factor(malform, labels = c("absent", "present")),
    mrace = factor(mrace,  c(1, 2, 3, 4, 8, 9), labels = c("White", "Black", "Asian"," Puerto Rican", "Other", "Unknown"))
    )

# quick overview
summary(child_data)

# check for missings (no missings)
sum(complete.cases(child_data))
sum(!complete.cases(child_data))
```
For my model, I did a quick topical overview and chose the variables that seemed most influential in affecting a baby's birthweight.
```{r, my model}
fit =
  lm(bwt ~ gaweeks + mrace + malform + pnumlbw + ppbmi, data = child_data) 
```

The following is a plot of residuals against fitted values from my model.
```{r, my plot residuals}
# why does it say r squared is missing?
child_data %>%
  add_residuals(fit) %>%
  add_predictions(fit) %>%
  ggplot(aes(x = pred, y = resid)) + 
  geom_point()  + 
  geom_smooth(se = FALSE) + 
  labs(title = "Predicted vs residuals", 
       x = "Predicted", 
       y = "Residuals")
```

In the following chunk I build two models to compare to the model that I built.
```{r, comparison models}
# One using length at birth and gestational age as predictors (main effects only)
fit_compare_1 = lm(bwt ~ blength + gaweeks, data = child_data) %>%
  broom::glance()

#One using head circumference, length, sex, and all interactions (including the three-way interaction) between these
fit_compare_2 = lm(bwt ~bhead*blength + bhead*babysex + blength*babysex + bhead*blength*babysex , data = child_data) %>%
  broom::glance()

```

The following chunk uses cross-validation to comparer the predictive performance of the three models.
```{r}
# get cross validation sample
cv_child_data = crossv_mc(child_data, 100)

# fit my candidate models above and assess prediction accuracy
cv_child_data %>% 
  mutate(fit  = map(cv_child_data, lm(bwt ~ gaweeks + mrace + malform + pnumlbw + ppbmi, data = .x)),
         fit_compare_1  = map(train, lm(bwt ~ blength + gaweeks, data = .x)),
         fit_compare_2  = map(train, lm(bwt ~bhead*blength + bhead*babysex + blength*babysex + bhead*blength*babysex, data = .x))
         )%>%
  mutate(rmse_fit = map2_dbl(linear_mod, test, ~rmse(model = .x, data = .y)),
         rmse_fit_compare_1 = map2_dbl(rmse_fit_compare_1, test, ~rmse(model = .x, data = .y)),
         rmse_fit_compare_2 = map2_dbl(fit_compare_2, test, ~rmse(model = .x, data = .y))
         )

# plot below shows the distribution of RMSE values for each candidate model
cv_child_data %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") %>% 
  mutate(model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse)) + geom_violin()

```




# Problem 2

```{r}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())

```

```{r}
# Produce estimates and plot r̂ 2
  weather_df %>% 
  # Get 5000 bootstrap samples
  modelr::bootstrap(n = 500) %>% 
  mutate(
    # simple linear model
    models = map(strap, ~lm(tmax ~ tmin, data = .x)),
    results = map(models, broom::glance)) %>%
    select(-strap, -models) %>% 
      unnest(results) %>%
     ggplot(aes(x = r.squared)) + geom_density()
```

```{r}
# plot  log(β̂ 0∗β)
  weather_df %>% 
  # Get 5000 bootstrap samples
  modelr::bootstrap(n = 500) %>% 
  mutate(
    # simple linear model
    models = map(strap, ~lm(tmax ~ tmin, data = .x)),
    results = map(models, broom::tidy)) %>%
    select(-strap, -models) %>% 
    unnest(results) %>%
    select(-std.error, -statistic, -p.value) %>% 
    pivot_wider(
    names_from = term, values_from = estimate) %>%
    rename(beta_0 = "(Intercept)") %>%
    mutate(ln_new = log(tmin*beta_0)
         ) %>%
     ggplot(aes(x = ln_new)) + geom_density()

```

  

Using the 5000 bootstrap estimates, identify the 2.5% and 97.5% quantiles to provide a 95% confidence interval for r̂ 2 and log(β̂ 0∗β̂ 1). Note: broom::glance() is helpful for extracting r̂ 2 from a fitted regression, and broom::tidy() (with some additional wrangling) should help in computing log(β̂ 0∗β̂ 1)
```{r}
# CI for r̂ 2
weather_df %>%
  filter(term == "r.squared") %>%
  ggplot(aes(x = r.squared)) + 
  geom_density() 

# CI for log(β̂ 0∗β)
weather_df %>%
  filter(term == "ln_new") %>%
  ggplot(aes(x = r.squared)) + 
  geom_density()

```


