---
title: "Homework 6"
author: "Laura Lynch"
date: "Nov 25 2019"
output: github_document
---

Setup chunk:
```{r}
library(tidyverse)
library(modelr)
knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%"
)
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)
scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
theme_set(theme_minimal() + theme(legend.position = "bottom"))
set.seed(1)
```

# Problem 1

In the following chunck I load and tidy the dataset, creating factor variables for the categorical variables. I also quickly overview the data and check for missing data (there are none).
```{r}
child_data = 
  readr::read_csv("data/birthweight.csv") %>%
  janitor::clean_names() %>%
    mutate(
    babysex = factor(babysex, labels = c("male", "female")),
    frace = factor(frace, levels = c(1, 2, 3, 4, 8, 9), labels = c("White", "Black", "Asian"," Puerto Rican", "Other", "Unknown")),
    malform = factor(malform, labels = c("absent", "present")),
    mrace = factor(mrace,  c(1, 2, 3, 4, 8, 9), labels = c("White", "Black", "Asian"," Puerto Rican", "Other", "Unknown"))
    )

# quick overview
summary(child_data)

# check for missings (no missings)
sum(complete.cases(child_data))
sum(!complete.cases(child_data))
```
For my model, I did a quick topical overview and chose the variables that seemed most influential in affecting a baby's birthweight.
```{r, my model}
fit =
  lm(bwt ~ gaweeks + mrace + malform + pnumlbw + ppbmi, data = child_data) 
```

The following is a plot of residuals against fitted values from my model.
```{r, my plot residuals}
child_data %>%
  add_residuals(fit) %>%
  add_predictions(fit) %>%
  ggplot(aes(x = pred, y = resid)) + 
  geom_point()  + 
  geom_smooth(se = FALSE) + 
  labs(title = "Predicted vs residuals", 
       x = "Predicted", 
       y = "Residuals")
```

In the following chunk I build two models to compare to the model that I built.
```{r, comparison models}
# One using length at birth and gestational age as predictors (main effects only)
model2 = lm(bwt ~ blength + gaweeks, data = child_data) %>%
  broom::glance()

#One using head circumference, length, sex, and all interactions (including the three-way interaction) between these
model3 = lm(bwt ~bhead*blength + bhead*babysex + blength*babysex + bhead*blength*babysex , data = child_data) %>%
  broom::glance()

```

The following chunk uses cross-validation to comparer the predictive performance of the three models.
```{r}
# get cross validation train/test sets
cv_child_data = 
  crossv_mc(child_data, 100) 

# make cv data into tibbles
cv_child_data =
  cv_child_data %>% 
  mutate(train = map(train, as_tibble),
         test = map(test, as_tibble))
```

```{r}
# fit my candidate models above and assess prediction accuracy
cv_child_data =
  cv_child_data %>% 
  mutate(
    fit = map(train, ~lm(bwt ~ gaweeks + mrace + malform + pnumlbw + ppbmi, data = .x)),
    model2  = map(train, ~lm(bwt ~ blength + gaweeks, data = .x)),
    model3  = map(train, ~lm(bwt ~ bhead*blength + bhead*babysex + blength*babysex + bhead*blength*babysex, data = .x))
    ) %>%
      mutate(
        rmse_fit = map2_dbl(fit, test, ~rmse(model = .x, data = .y)),
        rmse_model2 = map2_dbl(model2, test, ~rmse(model = .x, data = .y)),
        rmse_model3 = map2_dbl(model3, test, ~rmse(model = .x, data = .y))
        )
```

```{r}
# plot below shows the distribution of RMSE values for each candidate model
cv_child_data %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse") %>% 
  mutate(model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse)) + geom_violin()
```
The third model with the interaction terms is the best model as it has the lowest mean squared.



# Problem 2

```{r}
set.seed(1)

weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())

```

```{r}
r_squared =
# Produce estimates and plot r̂ 2
  weather_df %>% 
  # Get 5000 bootstrap samples
  modelr::bootstrap(n = 5000) %>% 
  mutate(
    # simple linear model
    models = map(strap, ~lm(tmax ~ tmin, data = .x)),
    results = map(models, broom::glance)) %>%
    select(-strap, -models) %>% 
      unnest(results) 

r_squared %>% ggplot(aes(x = r.squared)) + geom_density()
```

```{r}
ln_new_plot= 
# plot  log(β̂ 0∗β)
  weather_df %>% 
  # Get 5000 bootstrap samples
  modelr::bootstrap(n = 5000) %>% 
  mutate(
    # simple linear model
    models = map(strap, ~lm(tmax ~ tmin, data = .x)),
    results = map(models, broom::tidy)) %>%
    select(-strap, -models) %>% 
    unnest(results) %>%
    select(-std.error, -statistic, -p.value) %>% 
    pivot_wider(
    names_from = term, values_from = estimate) %>%
    rename(beta_0 = "(Intercept)") %>%
    mutate(ln_new = log(tmin*beta_0)
         ) 

ln_new_plot %>%
  ggplot(aes(x = ln_new)) + geom_density()

```

This is the 95% confidence interval for the r-squared distrribution:
```{r}
r2r_CI = quantile(r_squared$r.squared, prob = c(0.025, 0.975)) 
r2r_CI
```
This is the 95% confidence interval for the log of the intercept*Beta_1 distrribution:
```{r}
log_CI = quantile(ln_new_plot$ln_new, prob = c(0.025, 0.975)) 
log_CI
```


